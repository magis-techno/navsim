#!/usr/bin/env python3
"""
NAVSIM Dataset Download Status Checker
æ£€æŸ¥NAVSIMæ•°æ®é›†çš„ä¸‹è½½çŠ¶æ€
"""

import os
import sys
import json
from pathlib import Path
from collections import defaultdict

def check_path_exists(path_str, description):
    """æ£€æŸ¥è·¯å¾„æ˜¯å¦å­˜åœ¨å¹¶è¿”å›çŠ¶æ€"""
    path = Path(path_str).expanduser()
    if path.exists():
        if path.is_dir():
            item_count = len(list(path.iterdir())) if path.is_dir() else 0
            size = sum(f.stat().st_size for f in path.rglob('*') if f.is_file())
            size_mb = size / (1024 * 1024)
            return {
                'exists': True,
                'type': 'directory',
                'items': item_count,
                'size_mb': round(size_mb, 2),
                'path': str(path)
            }
        else:
            size = path.stat().st_size / (1024 * 1024)
            return {
                'exists': True,
                'type': 'file',
                'size_mb': round(size, 2),
                'path': str(path)
            }
    else:
        return {
            'exists': False,
            'type': 'missing',
            'path': str(path)
        }

def check_environment_variables():
    """æ£€æŸ¥ç¯å¢ƒå˜é‡è®¾ç½®"""
    env_vars = {
        'NUPLAN_MAP_VERSION': os.getenv('NUPLAN_MAP_VERSION'),
        'NUPLAN_MAPS_ROOT': os.getenv('NUPLAN_MAPS_ROOT'),
        'NAVSIM_EXP_ROOT': os.getenv('NAVSIM_EXP_ROOT'),
        'NAVSIM_DEVKIT_ROOT': os.getenv('NAVSIM_DEVKIT_ROOT'),
        'OPENSCENE_DATA_ROOT': os.getenv('OPENSCENE_DATA_ROOT')
    }
    
    print("ğŸ”§ ç¯å¢ƒå˜é‡æ£€æŸ¥:")
    print("=" * 50)
    for var, value in env_vars.items():
        if value:
            print(f"âœ… {var}: {value}")
        else:
            print(f"âŒ {var}: æœªè®¾ç½®")
    print()
    return env_vars

def get_expected_structure():
    """å®šä¹‰æœŸæœ›çš„ç›®å½•ç»“æ„"""
    return {
        'maps': {
            'description': 'nuPlan Maps',
            'paths': [
                '~/navsim_workspace/dataset/maps',
                './download/maps',
                './maps'
            ]
        },
        'mini_logs': {
            'description': 'Mini Dataset Logs',
            'paths': [
                '~/navsim_workspace/dataset/navsim_logs/mini',
                './download/mini_navsim_logs',
                './mini_navsim_logs'
            ]
        },
        'mini_sensors': {
            'description': 'Mini Dataset Sensor Blobs',
            'paths': [
                '~/navsim_workspace/dataset/sensor_blobs/mini',
                './download/mini_sensor_blobs',
                './mini_sensor_blobs'
            ]
        },
        'trainval_logs': {
            'description': 'TrainVal Dataset Logs',
            'paths': [
                '~/navsim_workspace/dataset/navsim_logs/trainval',
                './download/trainval_navsim_logs',
                './trainval_navsim_logs'
            ]
        },
        'trainval_sensors': {
            'description': 'TrainVal Dataset Sensor Blobs',
            'paths': [
                '~/navsim_workspace/dataset/sensor_blobs/trainval',
                './download/trainval_sensor_blobs',
                './trainval_sensor_blobs'
            ]
        },
        'test_logs': {
            'description': 'Test Dataset Logs',
            'paths': [
                '~/navsim_workspace/dataset/navsim_logs/test',
                './download/test_navsim_logs',
                './test_navsim_logs'
            ]
        },
        'test_sensors': {
            'description': 'Test Dataset Sensor Blobs',
            'paths': [
                '~/navsim_workspace/dataset/sensor_blobs/test',
                './download/test_sensor_blobs',
                './test_sensor_blobs'
            ]
        },
        'navhard_two_stage': {
            'description': 'NavHard Two Stage Dataset',
            'paths': [
                '~/navsim_workspace/dataset/navhard_two_stage',
                './download/navhard_two_stage',
                './navhard_two_stage'
            ]
        },
        'warmup_two_stage': {
            'description': 'Warmup Two Stage Dataset',
            'paths': [
                '~/navsim_workspace/dataset/warmup_two_stage',
                './download/warmup_two_stage',
                './warmup_two_stage'
            ]
        },
        'private_test_hard_two_stage': {
            'description': 'Private Test Hard Two Stage',
            'paths': [
                '~/navsim_workspace/dataset/private_test_hard_two_stage',
                './download/private_test_hard_two_stage',
                './private_test_hard_two_stage'
            ]
        },
        'private_test_hard_logs': {
            'description': 'Private Test Hard Logs',
            'paths': [
                '~/navsim_workspace/dataset/navsim_logs/private_test_hard',
                './download/private_test_hard_navsim_log',
                './private_test_hard_navsim_log'
            ]
        },
        'private_test_hard_sensors': {
            'description': 'Private Test Hard Sensor Blobs',
            'paths': [
                '~/navsim_workspace/dataset/sensor_blobs/private_test_hard',
                './download/private_test_hard_navsim_sensor',
                './private_test_hard_navsim_sensor'
            ]
        }
    }

def check_download_status():
    """æ£€æŸ¥æ‰€æœ‰æ•°æ®é›†çš„ä¸‹è½½çŠ¶æ€"""
    print("ğŸ” NAVSIM æ•°æ®é›†ä¸‹è½½çŠ¶æ€æ£€æŸ¥")
    print("=" * 60)
    
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    env_vars = check_environment_variables()
    
    # æ£€æŸ¥æ•°æ®é›†çŠ¶æ€
    structure = get_expected_structure()
    found_data = {}
    total_size = 0
    
    print("ğŸ“ æ•°æ®é›†çŠ¶æ€æ£€æŸ¥:")
    print("=" * 50)
    
    for dataset_key, dataset_info in structure.items():
        print(f"\nğŸ”¸ {dataset_info['description']}:")
        found = False
        
        for path_str in dataset_info['paths']:
            status = check_path_exists(path_str, dataset_info['description'])
            if status['exists']:
                print(f"   âœ… æ‰¾åˆ°: {status['path']}")
                if status['type'] == 'directory':
                    print(f"      ğŸ“‚ {status['items']} ä¸ªé¡¹ç›®, {status['size_mb']:.1f} MB")
                else:
                    print(f"      ğŸ“„ {status['size_mb']:.1f} MB")
                found_data[dataset_key] = status
                total_size += status['size_mb']
                found = True
                break
            
        if not found:
            print(f"   âŒ æœªæ‰¾åˆ°")
            # æ˜¾ç¤ºæŸ¥æ‰¾çš„è·¯å¾„
            for path_str in dataset_info['paths']:
                print(f"      ğŸ” å·²æ£€æŸ¥: {Path(path_str).expanduser()}")
    
    # æ€»ç»“
    print(f"\nğŸ“Š æ€»ç»“:")
    print("=" * 50)
    print(f"âœ… å·²æ‰¾åˆ°æ•°æ®é›†: {len(found_data)}/{len(structure)}")
    print(f"ğŸ’¾ æ€»æ•°æ®å¤§å°: {total_size:.1f} MB ({total_size/1024:.1f} GB)")
    
    # æ£€æŸ¥å‹ç¼©åŒ…æ®‹ç•™
    print(f"\nğŸ—‘ï¸ å‹ç¼©åŒ…æ®‹ç•™æ£€æŸ¥:")
    print("=" * 50)
    
    archive_patterns = [
        '*.tgz', '*.tar.gz', '*.zip', '*.tar'
    ]
    
    search_dirs = ['./download', '.', '~/navsim_workspace/dataset']
    for search_dir in search_dirs:
        search_path = Path(search_dir).expanduser()
        if search_path.exists():
            for pattern in archive_patterns:
                archives = list(search_path.glob(pattern))
                if archives:
                    print(f"ğŸ“ {search_dir}:")
                    for archive in archives:
                        size_mb = archive.stat().st_size / (1024 * 1024)
                        print(f"   ğŸ“¦ {archive.name} ({size_mb:.1f} MB)")
    
    # ç”ŸæˆçŠ¶æ€æŠ¥å‘Š
    report = {
        'timestamp': str(Path.cwd()),
        'environment_variables': env_vars,
        'found_datasets': found_data,
        'total_size_mb': total_size,
        'completion_rate': len(found_data) / len(structure)
    }
    
    # ä¿å­˜çŠ¶æ€æŠ¥å‘Š
    report_file = Path('./download_status_report.json')
    with open(report_file, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    
    return found_data, total_size

def suggest_next_steps(found_data):
    """å»ºè®®ä¸‹ä¸€æ­¥æ“ä½œ"""
    all_datasets = set(get_expected_structure().keys())
    missing_datasets = all_datasets - set(found_data.keys())
    
    print(f"\nğŸ’¡ å»ºè®®çš„ä¸‹ä¸€æ­¥æ“ä½œ:")
    print("=" * 50)
    
    if missing_datasets:
        print("âŒ ç¼ºå¤±çš„æ•°æ®é›†:")
        for dataset in missing_datasets:
            description = get_expected_structure()[dataset]['description']
            print(f"   â€¢ {description} ({dataset})")
        
        print(f"\nğŸš€ ä½ å¯ä»¥:")
        print("1. ä½¿ç”¨æˆ‘æ¥ä¸‹æ¥åˆ›å»ºçš„æ™ºèƒ½ä¸‹è½½è„šæœ¬")
        print("2. æˆ–æ‰‹åŠ¨è¿è¡Œå¯¹åº”çš„ä¸‹è½½è„šæœ¬:")
        
        script_mapping = {
            'maps': 'download_maps.sh',
            'mini_logs': 'download_mini.sh',
            'mini_sensors': 'download_mini.sh',
            'trainval_logs': 'download_trainval.sh', 
            'trainval_sensors': 'download_trainval.sh',
            'test_logs': 'download_test.sh',
            'test_sensors': 'download_test.sh',
            'navhard_two_stage': 'download_navhard_two_stage.sh',
            'warmup_two_stage': 'download_warmup_two_stage.sh',
            'private_test_hard_two_stage': 'download_private_test_hard_two_stage.sh',
            'private_test_hard_logs': 'download_private_test_hard_two_stage.sh',
            'private_test_hard_sensors': 'download_private_test_hard_two_stage.sh'
        }
        
        for dataset in missing_datasets:
            if dataset in script_mapping:
                print(f"   â€¢ {script_mapping[dataset]} (for {dataset})")
    else:
        print("ğŸ‰ æ‰€æœ‰æ•°æ®é›†éƒ½å·²ä¸‹è½½å®Œæˆ!")
        print("ğŸ“ å»ºè®®æŒ‰ç…§install.mdæ•´ç†ç›®å½•ç»“æ„")

if __name__ == "__main__":
    try:
        found_data, total_size = check_download_status()
        suggest_next_steps(found_data)
        
    except KeyboardInterrupt:
        print("\n\nğŸ›‘ æ£€æŸ¥è¢«ä¸­æ–­")
        sys.exit(1)
    except Exception as e:
        print(f"\nâŒ æ£€æŸ¥è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
        sys.exit(1) 